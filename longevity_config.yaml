# ═══════════════════════════════════════════════════════════════════
# Configuration — Neural Longevity Dataset Builder
# ═══════════════════════════════════════════════════════════════════

project:
  name: "longevity_markers"
  description: "Discovery of longevity-associated genetic and epigenetic markers"
  output_dir: "longevity_dataset"

# ═══════════════════════════════════════════════════════════════════
# Data Sources
# ═══════════════════════════════════════════════════════════════════

data_sources:
  # Reference genome (first resolved relative to /dados/GENOMICS_DATA/top3/)
  reference:
    fasta: "refs/reference.fa"   # falls back to this YAML directory/current cwd if needed
    name: "GRCh38"

  # Longevous cohort (temporarily reusing 1000 Genomes high-coverage data)
  longevous:
    ena_project: "PRJEB31736"
    sample_range: [0, 4]         # inclusive start, exclusive end
    label: 1                     # class label for longevous individuals

  # Non-longevous cohort (placeholder range within the same project)
  non_longevous:
    ena_project: "PRJEB31736"
    sample_range: [10, 14]       # inclusive start, exclusive end
    label: 0                     # class label for non-longevous individuals

# ═══════════════════════════════════════════════════════════════════
# Variant Selection
# ═══════════════════════════════════════════════════════════════════

variant_selection:
  # Initial strategy: use the first longevous individual to seed central points
  initial_strategy: "first_longevous_sample"
  # Number of loci to extract around the seed variants
  n_central_points: 10
  filters:
    # Minimum QUAL accepted for a variant
    min_quality: 30
    # Minimum depth (DP) required at the variant site
    min_depth: 10
    # Only retain variants marked as PASS in the FILTER column
    filter_pass_only: true
    # Skip variants with high population allele frequency
    exclude_common: true
    max_allele_frequency: 0.5
  refinement:
    # Post-processing refinement is disabled by default
    enabled: false
    method: "importance_ranking"
    top_k: 50

# ═══════════════════════════════════════════════════════════════════
# Sequence Extraction
# ═══════════════════════════════════════════════════════════════════

sequence_extraction:
  # Window length around each central point (must match AlphaGenome supported sizes)
  window_size: 2048
  # Ensure the variant is positioned in the middle of the window
  center_on_variant: true
  # Replace the reference allele with the alternate allele in the FASTA sequence
  use_alternate_allele: true

# ═══════════════════════════════════════════════════════════════════
# AlphaGenome
# ═══════════════════════════════════════════════════════════════════

alphagenome:
  # API token expected in the environment (or override in CI)
  api_key: "${ALPHAGENOME_API_KEY}"
  outputs:
    - "RNA_SEQ"
    - "CAGE"
    - "ATAC"
    - "CHIP_HISTONE"
    - "CHIP_TF"
    - "DNASE"
    - "PROCAP"
  ontology_terms:
    - "UBERON:0000955"  # Brain
    - "UBERON:0002107"  # Liver
    - "UBERON:0000948"  # Heart
    - "UBERON:0002048"  # Lung
    - "UBERON:0002113"  # Kidney
  # Cache AlphaGenome responses to avoid repeated network calls
  cache_results: true
  cache_dir: "alphagenome_cache"
  # Batch prediction parameters and retry policy
  batch_size: 10
  max_retries: 3
  retry_delay: 5

# ═══════════════════════════════════════════════════════════════════
# Dataset Assembly
# ═══════════════════════════════════════════════════════════════════

dataset:
  # Proportions used when generating train/validation/test splits
  splits:
    train: 0.6
    validation: 0.2
    test: 0.2
  # Enforce balanced class counts per split
  balance_classes: true
  # Seed to ensure reproducible shuffling and splits
  random_seed: 42
  features:
    sequence:
      # Encode nucleotide sequences as one-hot tensors
      enabled: true
      encoding: "one_hot"
    position:
      # Include normalized genomic coordinates as features
      enabled: true
      normalize: true
    alphagenome_predictions:
      # Summaries derived from AlphaGenome predictions
      enabled: true
      aggregation: "statistics"
      statistics: ["mean", "std", "min", "max", "median"]
    metadata:
      # Additional contextual information stored alongside each example
      enabled: true
      fields:
        - "sample_id"
        - "chromosome"
        - "position"
        - "ref_allele"
        - "alt_allele"
        - "variant_type"
        - "genotype"
        - "allele_used"
  transforms:
    # Data augmentation hooks (disabled by default for genomics)
    enabled: false
    methods: []

# ═══════════════════════════════════════════════════════════════════
# Pipeline Execution
# ═══════════════════════════════════════════════════════════════════

pipeline:
  # High-level pipeline toggles (disable steps to resume from mid-process)
  steps:
    download_samples: false
    select_central_points: true
    extract_sequences: false
    run_alphagenome: false
    build_dataset: false
  parallel:
    # Worker pool used for CPU-bound steps (downloads, variant parsing)
    enabled: true
    n_workers: 4
  # Allow reruns to pick up from the last saved state
  resume_from_checkpoint: true
  # Persist progress every N processed samples
  checkpoint_frequency: 10

# ═══════════════════════════════════════════════════════════════════
# Resource Management
# ═══════════════════════════════════════════════════════════════════

resources:
  # Soft limits for local resource planners
  max_memory_gb: 32
  max_disk_gb: 100
  temp_dir: "/tmp/longevity_processing"

# ═══════════════════════════════════════════════════════════════════
# Logging & Debug
# ═══════════════════════════════════════════════════════════════════

logging:
  # Log verbosity and destinations
  level: "INFO"
  log_file: "longevity_dataset/processing.log"
  console_output: true

debug:
  # Developer conveniences for partial or exploratory runs
  dry_run: false
  limit_samples: null
  save_intermediate: true
